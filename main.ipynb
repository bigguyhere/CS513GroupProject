{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.inspection as skli\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and join tables\n",
    "dir = os.getcwd()\n",
    "\n",
    "leaderboards = pds.read_csv(os.path.join(os.getcwd(),\"data\\\\v1\\\\leaderboards-data.csv\"), parse_dates=['date', 'verifiedDate'])\n",
    "games = pds.read_csv(os.path.join(os.getcwd(),\"data\\\\v1\\\\games-data.csv\"), parse_dates=['releaseDate', 'createdDate'])\n",
    "users = pds.read_csv(os.path.join(os.getcwd(),\"data\\\\v1\\\\users-data.csv\"), parse_dates=['signupDate'])\n",
    "categories = pds.read_csv(os.path.join(os.getcwd(),\"data\\\\v1\\\\categories-data.csv\"))\n",
    "\n",
    "data_frame = leaderboards.merge(games, left_on=\"gameID\", right_on=\"ID\", how=\"left\", suffixes=('_df1', '_gme'))\n",
    "data_frame = data_frame.merge(users, left_on=\"players\", right_on=\"ID\", how=\"left\", suffixes=('_df2', '_usr'))\n",
    "data_frame = data_frame.merge(categories, left_on=\"categoryID\", right_on=\"ID\", how=\"left\", suffixes=('_df3', '_cat'))\n",
    "\n",
    "data_frame = data_frame.drop(columns=['ID_df2', 'name_df2', 'URL', 'name_usr', 'parentGameID', 'ID_usr', 'name', 'rules', 'variablesAndValues', 'ID'])\n",
    " \n",
    "display(data_frame)\n",
    "# Split players rows where there are multiple players into multiple rows \n",
    "cols = list(data_frame.columns.drop('players' ))\n",
    "data_frame = (data_frame\n",
    "   .set_index(cols)\n",
    "   .stack()\n",
    "   .str.split(',', expand=True)\n",
    "   .stack()\n",
    "   .unstack(-2)\n",
    "   .reset_index(-1, drop=True)\n",
    "   .reset_index()\n",
    ")\n",
    "\n",
    "for col in data_frame.columns[data_frame.dtypes == 'object']:\n",
    "    data_frame[col] = data_frame[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Table\n",
    "\n",
    "pds.set_option('display.max_columns', None)\n",
    "display(data_frame)\n",
    "print(data_frame.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "def replaceNaNsWithMostFrequent(value):\n",
    "    return value.fillna(value.mode()[0])\n",
    "\n",
    "def replaceNaNsWithMean(value):\n",
    "    return value.fillna(value.mean())\n",
    "\n",
    "def mapValuesToIntegers(value):\n",
    "    return value.cat.codes\n",
    "\n",
    "def convertToUNIXTimestamp(date):\n",
    "    return (date.fillna(\"1970-01-01\").astype('int64') // (10**9)).replace(0, np.NaN)\n",
    "\n",
    "vals = data_frame.drop(columns=['runID', 'levelID', 'emulated']).isnull().sum()\n",
    "cols = data_frame.columns.drop(['runID', 'levelID', 'emulated'])[vals != 0]\n",
    "vals = vals[vals != 0]\n",
    "plt.figure(figsize= (15, 6))\n",
    "plt.bar(cols, vals, width=0.3)\n",
    "plt.ylabel(\"Amount of NAs in the dataset\")\n",
    "plt.xlabel(\"Column label (Columns with 0 NAs not shown)\")\n",
    "plt.show()\n",
    "\n",
    "data_frame[['date', \n",
    "            'verifiedDate', \n",
    "            'releaseDate', \n",
    "            'createdDate', \n",
    "            'signupDate']] = data_frame[['date', \n",
    "                                         'verifiedDate', \n",
    "                                         'releaseDate', \n",
    "                                         'createdDate', \n",
    "                                         'signupDate']].apply(convertToUNIXTimestamp)\n",
    "data_frame[['date', \n",
    "            'verifiedDate', \n",
    "            'releaseDate', \n",
    "            'createdDate', \n",
    "            'signupDate',\n",
    "            'numRuns']] = data_frame[['date', \n",
    "                                         'verifiedDate', \n",
    "                                         'releaseDate', \n",
    "                                         'createdDate', \n",
    "                                         'signupDate',\n",
    "                                         'numRuns']].apply(replaceNaNsWithMean)\n",
    "\n",
    "for col in data_frame.columns[data_frame.dtypes == 'category']:\n",
    "    data_frame[[col]] = data_frame[[col]].apply(replaceNaNsWithMostFrequent)\n",
    "    data_frame[[col]] = data_frame[[col]].apply(mapValuesToIntegers)\n",
    "\n",
    "display(data_frame)\n",
    "print(data_frame.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    "minmax = data_frame.copy(deep=True)\n",
    "\n",
    "for col in data_frame.columns[data_frame.dtypes != 'bool']:\n",
    "    minimum = data_frame[col].min()\n",
    "    minmax[col] = (data_frame[col] - minimum) / (data_frame[col].max() - minimum)\n",
    "\n",
    "display(data_frame)\n",
    "print(data_frame.isnull().sum())\n",
    "display(minmax)\n",
    "print(minmax.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-Train Split + Downsampling\n",
    "rdm_seed = 404\n",
    "\n",
    "minmax_majority = minmax[minmax['emulated'] == False]\n",
    "minmax_minority = minmax[minmax['emulated'] == True]\n",
    "\n",
    "mm_downsampled = resample(minmax_majority, \n",
    "                                 replace=False,    \n",
    "                                 n_samples=len(minmax_minority),  \n",
    "                                 random_state=rdm_seed) \n",
    "\n",
    "minmax = pds.concat([mm_downsampled, minmax_minority])\n",
    " \n",
    "# Display new class counts\n",
    "print(np.unique(minmax['emulated'], return_counts=True))\n",
    "\n",
    "target = minmax['emulated']\n",
    "\n",
    "plt.figure(figsize= (15, 6))\n",
    "plt.bar([\"Non-Emulated Pre-Downsampling\", \"Emulated Pre-Downsampling\", \"Non-Emulated Post-Downsampling\", \"Emulated Post-Downsampling\"], \n",
    "        [minmax_majority.size, minmax_minority.size, (minmax[minmax['emulated'] == False]).size, (minmax[minmax['emulated'] == True]).size],\n",
    "        width=0.5, color=['lightblue', 'orange', 'lightblue', 'orange'])\n",
    "plt.ylabel(\"Amount of Entries in Dataset\")\n",
    "plt.show()\n",
    "\n",
    "minmax = minmax.drop(columns=['runID', 'levelID', 'emulated'])\n",
    "\n",
    "minmax_train, minmax_test, mm_target_train, mm_target_test  = train_test_split(minmax, target,test_size = 0.33, random_state = rdm_seed, shuffle = True)\n",
    "display(minmax_train)\n",
    "display(minmax_test)\n",
    "display(mm_target_train)\n",
    "display(mm_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyArr = [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "modelNames = [\"KNN\", \"Multinomial NB\", \"RandomForest\", \"Logistic Regression\", \"Decision Tree\", \"AdaBoost\", \"Multi-Layered Perceptron\", \"Bagging\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors = k)\n",
    "knn.fit(minmax_train, mm_target_train)\n",
    "target_pred = knn.predict(minmax_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Post-Run Statistics\n",
    "\n",
    "accuracy = accuracy_score(mm_target_test,target_pred) * 100\n",
    "accuracyArr[0] = accuracy\n",
    "conMatrix = confusion_matrix(mm_target_test, target_pred)\n",
    "\n",
    "print(f'Accuracy of model with k = {k}: {accuracy}%\\n')\n",
    "print(f'Classification Report:\\n {classification_report(mm_target_test, target_pred)}')\n",
    "ConfusionMatrixDisplay(conMatrix, display_labels=[\"Not Emulated\", \"Emulated\"],).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "\n",
    "MNNB = MultinomialNB()\n",
    "MNNB.fit(minmax_train, mm_target_train)\n",
    "target_pred = MNNB.predict(minmax_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial NB Post-Run Statistics\n",
    "\n",
    "accuracy = accuracy_score(mm_target_test,target_pred) * 100\n",
    "accuracyArr[1] = accuracy\n",
    "conMatrix = confusion_matrix(mm_target_test, target_pred)\n",
    "\n",
    "print(f'Accuracy of model: {accuracy}%\\n')\n",
    "print(f'Classification Report:\\n {classification_report(mm_target_test, target_pred)}')\n",
    "ConfusionMatrixDisplay(conMatrix, display_labels=[\"Not Emulated\", \"Emulated\"],).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "randomForest = RandomForestClassifier(n_estimators=200, random_state=rdm_seed, class_weight='balanced')\n",
    "randomForest.fit(minmax_train,mm_target_train)\n",
    "target_pred = randomForest.predict(minmax_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Post-Run Statistics\n",
    "\n",
    "accuracy = accuracy_score(mm_target_test,target_pred) * 100\n",
    "accuracyArr[2] = accuracy\n",
    "conMatrix = confusion_matrix(mm_target_test, target_pred)\n",
    "\n",
    "print(f'Accuracy of model: {accuracy}%\\n')\n",
    "print(f'Classification Report:\\n {classification_report(mm_target_test, target_pred)}')\n",
    "ConfusionMatrixDisplay(conMatrix, display_labels=[\"Not Emulated\", \"Emulated\"],).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logReg = LogisticRegression(random_state=rdm_seed, class_weight='balanced')\n",
    "logReg.fit(minmax_train, mm_target_train)\n",
    "target_pred = logReg.predict(minmax_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Post-Run Statistics\n",
    "\n",
    "accuracy = accuracy_score(mm_target_test,target_pred) * 100\n",
    "accuracyArr[3] = accuracy\n",
    "conMatrix = confusion_matrix(mm_target_test, target_pred)\n",
    "\n",
    "print(f'Accuracy of model: {accuracy}%\\n')\n",
    "print(f'Classification Report:\\n {classification_report(mm_target_test, target_pred)}')\n",
    "ConfusionMatrixDisplay(conMatrix, display_labels=[\"Not Emulated\", \"Emulated\"],).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "dTree = DecisionTreeClassifier(random_state=rdm_seed, class_weight='balanced')\n",
    "dTree.fit(minmax_train,mm_target_train)\n",
    "target_pred = dTree.predict(minmax_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Post-Run Statistics\n",
    "\n",
    "accuracy = accuracy_score(mm_target_test, target_pred) * 100\n",
    "accuracyArr[4] = accuracy\n",
    "conMatrix = confusion_matrix(mm_target_test, target_pred)\n",
    "\n",
    "print(f'Accuracy of model: {accuracy}%\\n')\n",
    "print(f'Classification Report:\\n {classification_report(mm_target_test, target_pred)}')\n",
    "ConfusionMatrixDisplay(conMatrix, display_labels=[\"Not Emulated\", \"Emulated\"],).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "\n",
    "adaBoost = AdaBoostClassifier(algorithm='SAMME', random_state=rdm_seed)\n",
    "adaBoost.fit(minmax_train,mm_target_train)\n",
    "target_pred = adaBoost.predict(minmax_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Post-Run Statistics\n",
    "\n",
    "accuracy = accuracy_score(mm_target_test, target_pred) * 100\n",
    "accuracyArr[5] = accuracy\n",
    "conMatrix = confusion_matrix(mm_target_test, target_pred)\n",
    "\n",
    "print(f'Accuracy of model: {accuracy}%\\n')\n",
    "print(f'Classification Report:\\n {classification_report(mm_target_test, target_pred)}')\n",
    "ConfusionMatrixDisplay(conMatrix, display_labels=[\"Not Emulated\", \"Emulated\"],).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Layered Perceptron\n",
    "\n",
    "MLP = MLPClassifier(random_state=rdm_seed, max_iter=1000)\n",
    "MLP.fit(minmax_train, mm_target_train)\n",
    "target_pred = MLP.predict(minmax_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Layered Perceptron Post-Run Statistics\n",
    "\n",
    "accuracy = accuracy_score(mm_target_test, target_pred) * 100\n",
    "accuracyArr[6] = accuracy\n",
    "conMatrix = confusion_matrix(mm_target_test, target_pred)\n",
    "\n",
    "print(f'Accuracy of model: {accuracy}%\\n')\n",
    "print(f'Classification Report:\\n {classification_report(mm_target_test, target_pred)}')\n",
    "ConfusionMatrixDisplay(conMatrix, display_labels=[\"Not Emulated\", \"Emulated\"],).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging Classifier\n",
    "\n",
    "bgc=BaggingClassifier()\n",
    "bgc.fit(minmax_train, mm_target_train)  \n",
    "target_pred = bgc.predict(minmax_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging Classifier Statistics\n",
    "\n",
    "accuracy = accuracy_score(mm_target_test,target_pred) * 100\n",
    "accuracyArr[7] = accuracy\n",
    "conMatrix = confusion_matrix(mm_target_test, target_pred)\n",
    "\n",
    "print(f'Accuracy of model: {accuracy}%\\n')\n",
    "print(f'Classification Report:\\n {classification_report(mm_target_test, target_pred)}')\n",
    "ConfusionMatrixDisplay(conMatrix, display_labels=[\"Not Emulated\", \"Emulated\"],).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = skli.permutation_importance(bgc, minmax_test, mm_target_test, n_repeats=30, random_state=rdm_seed)\n",
    "sorted_importances = importance.importances_mean.argsort()\n",
    "plt.barh(minmax_train.columns[sorted_importances], importance.importances_mean[sorted_importances])\n",
    "plt.xlabel(\"Permutation Importance Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data_frame.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool)) \n",
    "plt.figure(figsize=(10, 6)) \n",
    "heatmap = sns.heatmap(corr_matrix, mask=mask, vmin=-1, vmax=1, cmap='coolwarm')\n",
    "heatmap.set_title('Correlation Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracyArr)\n",
    "sorted_accuracies = np.array(accuracyArr).argsort()\n",
    "plt.barh(np.array(modelNames)[sorted_accuracies], np.array(accuracyArr)[sorted_accuracies], height=0.5)\n",
    "plt.xlabel(\"Model Accuracy (%)\")\n",
    "plt.ylabel(\"Name of Model\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
